# Generating Images using VAEs, DCGANs, and DDPMs (Diffusion)

## Overview
In this project, we will explore 3 image generation models: VAE, DCGAN, and DDPMs (diffusion). For each model, we discuss the theory and intuition before implementing each in Keras. Then we will generate images in the style of MNIST handwritten digits, which will allow us to compare and contrast the different models using the Generative Model Trilemma. Check out our blog post! 

## Reference
The implementation of the three models are heavily based on the following sources!

#### VAEs

1. https://www.tensorflow.org/tutorials/generative/cvae
2. https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73
3. https://arxiv.org/pdf/1907.08956.pdf

#### DCGANs

1. https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html
2. https://towardsdatascience.com/dcgans-deep-convolutional-generative-adversarial-networks-c7f392c2c8f8

#### DDPMs

1. https://learnopencv.com/image-generation-using-diffusion-models/ 
2. https://keras.io/examples/generative/ddpm/
3. https://medium.com/@vedantjumle/image-generation-with-diffusion-models-using-keras-and-tensorflow-9f60aae72ac


